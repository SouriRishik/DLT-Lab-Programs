{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf18d74-2e20-4c41-af2d-696433eef51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 08:31:24.037272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f63148-3e0a-4b26-9e5c-a73e41fd44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "epochs = 100  \n",
    "latent_dim = 256\n",
    "num_samples = 10000 \n",
    "data_path = \"/home/mca/Downloads/hin-eng/hin.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d66daac-fcbf-4f4a-9a21-1d0530419409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3116\n",
      "Number of unique input tokens: 70\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 107\n",
      "Max sequence length for outputs: 123\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37eb3cd9-55f7-4db7-b143-4102490f474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 08:41:58.745458: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21883cb2-5925-4177-a802-d7383bb4b15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 22s 512ms/step - loss: 1.2851 - accuracy: 0.7860 - val_loss: 1.8536 - val_accuracy: 0.6843\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 26s 658ms/step - loss: 1.0021 - accuracy: 0.8068 - val_loss: 1.9864 - val_accuracy: 0.6843\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 30s 778ms/step - loss: 0.9013 - accuracy: 0.8089 - val_loss: 1.4362 - val_accuracy: 0.6867\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 17s 446ms/step - loss: 0.8481 - accuracy: 0.8090 - val_loss: 1.4997 - val_accuracy: 0.6867\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 22s 562ms/step - loss: 0.8165 - accuracy: 0.8092 - val_loss: 1.4025 - val_accuracy: 0.6867\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 21s 523ms/step - loss: 0.8087 - accuracy: 0.8091 - val_loss: 1.3210 - val_accuracy: 0.6859\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 25s 643ms/step - loss: 0.7935 - accuracy: 0.8089 - val_loss: 1.3278 - val_accuracy: 0.6835\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 27s 698ms/step - loss: 0.7781 - accuracy: 0.8086 - val_loss: 1.3032 - val_accuracy: 0.6867\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 24s 596ms/step - loss: 0.7602 - accuracy: 0.8103 - val_loss: 1.3427 - val_accuracy: 0.6888\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 29s 748ms/step - loss: 0.7409 - accuracy: 0.8144 - val_loss: 2.1650 - val_accuracy: 0.6877\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 25s 639ms/step - loss: 0.7268 - accuracy: 0.8192 - val_loss: 1.1944 - val_accuracy: 0.6923\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 23s 605ms/step - loss: 0.7016 - accuracy: 0.8281 - val_loss: 1.1647 - val_accuracy: 0.7136\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 25s 639ms/step - loss: 0.6622 - accuracy: 0.8357 - val_loss: 1.1301 - val_accuracy: 0.7199\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 0.6471 - accuracy: 0.8382 - val_loss: 1.0880 - val_accuracy: 0.7223\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 24s 601ms/step - loss: 0.6186 - accuracy: 0.8418 - val_loss: 1.0443 - val_accuracy: 0.7308\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 28s 728ms/step - loss: 0.6048 - accuracy: 0.8435 - val_loss: 1.0500 - val_accuracy: 0.7287\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 30s 769ms/step - loss: 0.5943 - accuracy: 0.8474 - val_loss: 1.0075 - val_accuracy: 0.7373\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.5769 - accuracy: 0.8501 - val_loss: 1.0035 - val_accuracy: 0.7391\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 25s 642ms/step - loss: 0.5674 - accuracy: 0.8522 - val_loss: 0.9787 - val_accuracy: 0.7448\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 18s 453ms/step - loss: 0.5566 - accuracy: 0.8550 - val_loss: 0.9904 - val_accuracy: 0.7390\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5473 - accuracy: 0.8573 - val_loss: 0.9585 - val_accuracy: 0.7492\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 24s 627ms/step - loss: 0.6038 - accuracy: 0.8472 - val_loss: 0.9551 - val_accuracy: 0.7501\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 22s 561ms/step - loss: 0.5315 - accuracy: 0.8618 - val_loss: 0.9420 - val_accuracy: 0.7516\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 30s 782ms/step - loss: 0.5271 - accuracy: 0.8618 - val_loss: 0.9310 - val_accuracy: 0.7570\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 24s 606ms/step - loss: 0.5207 - accuracy: 0.8634 - val_loss: 0.9140 - val_accuracy: 0.7593\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 23s 588ms/step - loss: 0.5148 - accuracy: 0.8646 - val_loss: 0.9430 - val_accuracy: 0.7530\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 25s 638ms/step - loss: 0.5090 - accuracy: 0.8658 - val_loss: 0.9172 - val_accuracy: 0.7559\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 37s 951ms/step - loss: 0.5034 - accuracy: 0.8673 - val_loss: 0.9028 - val_accuracy: 0.7650\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 24s 614ms/step - loss: 0.4982 - accuracy: 0.8687 - val_loss: 0.8953 - val_accuracy: 0.7635\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 23s 603ms/step - loss: 0.4936 - accuracy: 0.8695 - val_loss: 0.8893 - val_accuracy: 0.7652\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 24s 611ms/step - loss: 0.4891 - accuracy: 0.8707 - val_loss: 0.8799 - val_accuracy: 0.7661\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 20s 513ms/step - loss: 0.4849 - accuracy: 0.8717 - val_loss: 0.8654 - val_accuracy: 0.7725\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 21s 540ms/step - loss: 0.4808 - accuracy: 0.8726 - val_loss: 0.8694 - val_accuracy: 0.7726\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 20s 485ms/step - loss: 0.4773 - accuracy: 0.8735 - val_loss: 0.8711 - val_accuracy: 0.7711\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 0.4734 - accuracy: 0.8741 - val_loss: 0.8615 - val_accuracy: 0.7752\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 18s 460ms/step - loss: 0.4706 - accuracy: 0.8744 - val_loss: 0.8594 - val_accuracy: 0.7712\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 25s 632ms/step - loss: 0.4673 - accuracy: 0.8750 - val_loss: 0.8579 - val_accuracy: 0.7730\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 25s 634ms/step - loss: 0.4637 - accuracy: 0.8761 - val_loss: 0.8553 - val_accuracy: 0.7745\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 24s 627ms/step - loss: 0.4611 - accuracy: 0.8769 - val_loss: 0.8389 - val_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 26s 622ms/step - loss: 0.4576 - accuracy: 0.8774 - val_loss: 0.8428 - val_accuracy: 0.7767\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 35s 903ms/step - loss: 0.4554 - accuracy: 0.8777 - val_loss: 0.8379 - val_accuracy: 0.7763\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 26s 664ms/step - loss: 0.4526 - accuracy: 0.8783 - val_loss: 0.8362 - val_accuracy: 0.7770\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 20s 498ms/step - loss: 0.4499 - accuracy: 0.8785 - val_loss: 0.8257 - val_accuracy: 0.7803\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 21s 532ms/step - loss: 0.4472 - accuracy: 0.8791 - val_loss: 0.8286 - val_accuracy: 0.7764\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 31s 768ms/step - loss: 0.4441 - accuracy: 0.8799 - val_loss: 0.8258 - val_accuracy: 0.7781\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 28s 713ms/step - loss: 0.4424 - accuracy: 0.8801 - val_loss: 0.8192 - val_accuracy: 0.7801\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 25s 648ms/step - loss: 0.4396 - accuracy: 0.8806 - val_loss: 0.8123 - val_accuracy: 0.7827\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 23s 590ms/step - loss: 0.4382 - accuracy: 0.8808 - val_loss: 0.8092 - val_accuracy: 0.7805\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 24s 617ms/step - loss: 0.4347 - accuracy: 0.8817 - val_loss: 0.8129 - val_accuracy: 0.7814\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 17s 443ms/step - loss: 0.4329 - accuracy: 0.8817 - val_loss: 0.8134 - val_accuracy: 0.7817\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 21s 540ms/step - loss: 0.4308 - accuracy: 0.8825 - val_loss: 0.7968 - val_accuracy: 0.7843\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 23s 589ms/step - loss: 0.4285 - accuracy: 0.8825 - val_loss: 0.8147 - val_accuracy: 0.7805\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 26s 657ms/step - loss: 0.4260 - accuracy: 0.8834 - val_loss: 0.8087 - val_accuracy: 0.7796\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 23s 591ms/step - loss: 0.4245 - accuracy: 0.8836 - val_loss: 0.7952 - val_accuracy: 0.7844\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.4224 - accuracy: 0.8840 - val_loss: 0.8018 - val_accuracy: 0.7831\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 28s 722ms/step - loss: 0.4205 - accuracy: 0.8844 - val_loss: 0.7959 - val_accuracy: 0.7833\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 24s 606ms/step - loss: 0.4183 - accuracy: 0.8849 - val_loss: 0.8022 - val_accuracy: 0.7855\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 20s 502ms/step - loss: 0.4166 - accuracy: 0.8851 - val_loss: 0.7893 - val_accuracy: 0.7864\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 28s 718ms/step - loss: 0.4144 - accuracy: 0.8855 - val_loss: 0.7882 - val_accuracy: 0.7856\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 18s 447ms/step - loss: 0.4128 - accuracy: 0.8863 - val_loss: 0.7922 - val_accuracy: 0.7841\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 19s 478ms/step - loss: 0.4225 - accuracy: 0.8847 - val_loss: 0.7797 - val_accuracy: 0.7876\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 28s 727ms/step - loss: 0.4079 - accuracy: 0.8874 - val_loss: 0.7838 - val_accuracy: 0.7870\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 20s 514ms/step - loss: 0.4086 - accuracy: 0.8869 - val_loss: 0.7770 - val_accuracy: 0.7881\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 21s 545ms/step - loss: 0.4062 - accuracy: 0.8874 - val_loss: 0.7776 - val_accuracy: 0.7887\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4040 - accuracy: 0.8880 - val_loss: 0.7795 - val_accuracy: 0.7874\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 22s 556ms/step - loss: 0.4024 - accuracy: 0.8886 - val_loss: 0.7823 - val_accuracy: 0.7871\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 24s 608ms/step - loss: 0.4009 - accuracy: 0.8889 - val_loss: 0.7766 - val_accuracy: 0.7885\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 22s 560ms/step - loss: 0.3986 - accuracy: 0.8900 - val_loss: 0.7830 - val_accuracy: 0.7880\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 33s 850ms/step - loss: 0.3975 - accuracy: 0.8897 - val_loss: 0.7805 - val_accuracy: 0.7875\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 35s 788ms/step - loss: 0.3952 - accuracy: 0.8902 - val_loss: 0.7712 - val_accuracy: 0.7901\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 22s 561ms/step - loss: 0.3935 - accuracy: 0.8908 - val_loss: 0.7872 - val_accuracy: 0.7883\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.3919 - accuracy: 0.8912 - val_loss: 0.7743 - val_accuracy: 0.7902\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 25s 652ms/step - loss: 0.3901 - accuracy: 0.8915 - val_loss: 0.7723 - val_accuracy: 0.7907\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 22s 550ms/step - loss: 0.3880 - accuracy: 0.8921 - val_loss: 0.7636 - val_accuracy: 0.7932\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 19s 479ms/step - loss: 0.3867 - accuracy: 0.8923 - val_loss: 0.7689 - val_accuracy: 0.7910\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 23s 587ms/step - loss: 0.3849 - accuracy: 0.8927 - val_loss: 0.7715 - val_accuracy: 0.7903\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 23s 569ms/step - loss: 0.3831 - accuracy: 0.8933 - val_loss: 0.7687 - val_accuracy: 0.7901\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 22s 533ms/step - loss: 0.3813 - accuracy: 0.8940 - val_loss: 0.7661 - val_accuracy: 0.7905\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.3797 - accuracy: 0.8941 - val_loss: 0.7705 - val_accuracy: 0.7907\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 27s 684ms/step - loss: 0.3784 - accuracy: 0.8950 - val_loss: 0.7663 - val_accuracy: 0.7928\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 27s 687ms/step - loss: 0.3767 - accuracy: 0.8952 - val_loss: 0.7689 - val_accuracy: 0.7930\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.3747 - accuracy: 0.8957 - val_loss: 0.7606 - val_accuracy: 0.7927\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 22s 562ms/step - loss: 0.3727 - accuracy: 0.8960 - val_loss: 0.7629 - val_accuracy: 0.7922\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 29s 716ms/step - loss: 0.3716 - accuracy: 0.8964 - val_loss: 0.7707 - val_accuracy: 0.7928\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 26s 681ms/step - loss: 0.3698 - accuracy: 0.8970 - val_loss: 0.7645 - val_accuracy: 0.7938\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.3680 - accuracy: 0.8975 - val_loss: 0.7590 - val_accuracy: 0.7944\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 23s 608ms/step - loss: 0.3670 - accuracy: 0.8977 - val_loss: 0.7676 - val_accuracy: 0.7922\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 27s 688ms/step - loss: 0.3652 - accuracy: 0.8983 - val_loss: 0.7654 - val_accuracy: 0.7922\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 33s 851ms/step - loss: 0.3627 - accuracy: 0.8991 - val_loss: 0.7634 - val_accuracy: 0.7936\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 20s 526ms/step - loss: 0.3614 - accuracy: 0.8990 - val_loss: 0.7631 - val_accuracy: 0.7945\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 26s 675ms/step - loss: 0.3600 - accuracy: 0.8994 - val_loss: 0.7672 - val_accuracy: 0.7930\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 30s 770ms/step - loss: 0.3580 - accuracy: 0.9003 - val_loss: 0.7617 - val_accuracy: 0.7932\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 25s 652ms/step - loss: 0.3564 - accuracy: 0.9009 - val_loss: 0.7672 - val_accuracy: 0.7928\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 22s 561ms/step - loss: 0.3547 - accuracy: 0.9014 - val_loss: 0.7635 - val_accuracy: 0.7940\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 24s 616ms/step - loss: 0.3533 - accuracy: 0.9017 - val_loss: 0.7618 - val_accuracy: 0.7958\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 30s 762ms/step - loss: 0.3511 - accuracy: 0.9021 - val_loss: 0.7709 - val_accuracy: 0.7932\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 26s 674ms/step - loss: 0.3499 - accuracy: 0.9024 - val_loss: 0.7604 - val_accuracy: 0.7954\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 27s 708ms/step - loss: 0.3482 - accuracy: 0.9029 - val_loss: 0.7642 - val_accuracy: 0.7945\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 19s 480ms/step - loss: 0.3465 - accuracy: 0.9034 - val_loss: 0.7730 - val_accuracy: 0.7921\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 20s 517ms/step - loss: 0.3444 - accuracy: 0.9040 - val_loss: 0.7823 - val_accuracy: 0.7894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8b3a356850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0938758f-fbc5-433e-a4b5-61df91e0dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, 70)]           0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None, 93)]           0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                334848    ['input_1[0][0]']             \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          358400    ['input_2[0][0]',             \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 93)             23901     ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 717149 (2.74 MB)\n",
      "Trainable params: 717149 (2.74 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b933a3f-695a-48b9-86ad-b0d664e85cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e17e8c3-f830-4480-b3d2-711425760353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"LSTM_model.keras\")\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb53a463-cdf0-4229-8752-987e704ac4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Duck!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Duck!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Exhale.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Exhale.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Inhale.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Inhale.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Thanks!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: मैं तुम्हारे साथ सात का किता है।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6619bf73-0ad6-4b14-8c44-e4332cc6d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def train_model(model, name):\n",
    "    model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        [encoder_input_data, decoder_input_data],\n",
    "        decoder_target_data,\n",
    "        batch_size=64,\n",
    "        epochs=30,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    model.save(f\"{name}_model.keras\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae9d1ad-26d5-406b-8e6b-bc76a583e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "def build_gru_model():\n",
    "    encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = GRU(256, return_state=True)\n",
    "    encoder_outputs, state_h = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h]\n",
    "\n",
    "    decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "    decoder_gru = GRU(256, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _ = decoder_gru(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f727d93-8cab-4498-8db0-43fc0bc7bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "39/39 [==============================] - 11s 236ms/step - loss: 1.3421 - accuracy: 0.7858 - val_loss: 1.7311 - val_accuracy: 0.6843\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 9s 220ms/step - loss: 0.9463 - accuracy: 0.8065 - val_loss: 1.4296 - val_accuracy: 0.6843\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 0.8814 - accuracy: 0.8069 - val_loss: 1.3984 - val_accuracy: 0.6864\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 14s 352ms/step - loss: 0.8235 - accuracy: 0.8082 - val_loss: 1.3221 - val_accuracy: 0.6814\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 14s 360ms/step - loss: 0.7826 - accuracy: 0.8089 - val_loss: 1.3103 - val_accuracy: 0.6868\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 13s 337ms/step - loss: 0.7405 - accuracy: 0.8169 - val_loss: 1.2054 - val_accuracy: 0.7028\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 13s 338ms/step - loss: 0.6968 - accuracy: 0.8267 - val_loss: 1.1484 - val_accuracy: 0.7115\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 12s 303ms/step - loss: 0.6602 - accuracy: 0.8373 - val_loss: 1.0908 - val_accuracy: 0.7251\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 14s 368ms/step - loss: 0.6253 - accuracy: 0.8421 - val_loss: 1.0449 - val_accuracy: 0.7315\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 14s 370ms/step - loss: 0.5994 - accuracy: 0.8463 - val_loss: 1.0164 - val_accuracy: 0.7364\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 13s 326ms/step - loss: 0.6331 - accuracy: 0.8447 - val_loss: 1.0035 - val_accuracy: 0.7369\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 14s 372ms/step - loss: 0.5706 - accuracy: 0.8510 - val_loss: 1.0049 - val_accuracy: 0.7346\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 14s 367ms/step - loss: 0.5588 - accuracy: 0.8539 - val_loss: 4.8876 - val_accuracy: 0.1556\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 13s 329ms/step - loss: 0.6812 - accuracy: 0.8355 - val_loss: 0.9551 - val_accuracy: 0.7485\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 12s 294ms/step - loss: 0.5404 - accuracy: 0.8582 - val_loss: 0.9415 - val_accuracy: 0.7511\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.5323 - accuracy: 0.8603 - val_loss: 0.9392 - val_accuracy: 0.7518\n",
      "Epoch 17/30\n",
      "39/39 [==============================] - 11s 279ms/step - loss: 0.5235 - accuracy: 0.8630 - val_loss: 0.9140 - val_accuracy: 0.7605\n",
      "Epoch 18/30\n",
      "39/39 [==============================] - 12s 303ms/step - loss: 0.5157 - accuracy: 0.8649 - val_loss: 0.9087 - val_accuracy: 0.7613\n",
      "Epoch 19/30\n",
      "39/39 [==============================] - 14s 369ms/step - loss: 0.5093 - accuracy: 0.8662 - val_loss: 0.9009 - val_accuracy: 0.7600\n",
      "Epoch 20/30\n",
      "39/39 [==============================] - 11s 294ms/step - loss: 0.5041 - accuracy: 0.8670 - val_loss: 0.9004 - val_accuracy: 0.7633\n",
      "Epoch 21/30\n",
      "39/39 [==============================] - 11s 286ms/step - loss: 0.4990 - accuracy: 0.8682 - val_loss: 0.8835 - val_accuracy: 0.7671\n",
      "Epoch 22/30\n",
      "39/39 [==============================] - 11s 294ms/step - loss: 0.4940 - accuracy: 0.8692 - val_loss: 0.8806 - val_accuracy: 0.7678\n",
      "Epoch 23/30\n",
      "39/39 [==============================] - 14s 354ms/step - loss: 0.4893 - accuracy: 0.8701 - val_loss: 0.8817 - val_accuracy: 0.7676\n",
      "Epoch 24/30\n",
      "39/39 [==============================] - 13s 347ms/step - loss: 0.4859 - accuracy: 0.8704 - val_loss: 0.8765 - val_accuracy: 0.7659\n",
      "Epoch 25/30\n",
      "39/39 [==============================] - 17s 433ms/step - loss: 0.4822 - accuracy: 0.8714 - val_loss: 0.8699 - val_accuracy: 0.7683\n",
      "Epoch 26/30\n",
      "39/39 [==============================] - 14s 358ms/step - loss: 0.4787 - accuracy: 0.8719 - val_loss: 0.8554 - val_accuracy: 0.7726\n",
      "Epoch 27/30\n",
      "39/39 [==============================] - 15s 390ms/step - loss: 0.4751 - accuracy: 0.8727 - val_loss: 0.8467 - val_accuracy: 0.7752\n",
      "Epoch 28/30\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.4721 - accuracy: 0.8734 - val_loss: 0.8515 - val_accuracy: 0.7739\n",
      "Epoch 29/30\n",
      "39/39 [==============================] - 13s 347ms/step - loss: 0.4693 - accuracy: 0.8737 - val_loss: 0.8417 - val_accuracy: 0.7760\n",
      "Epoch 30/30\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 0.4660 - accuracy: 0.8747 - val_loss: 0.8397 - val_accuracy: 0.7763\n"
     ]
    }
   ],
   "source": [
    "gru_model = build_gru_model()\n",
    "gru_history = train_model(gru_model, \"gru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfc841e4-88ea-4bc3-8fd9-fe6dfe304e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)       [(None, None, 70)]           0         []                            \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)       [(None, None, 93)]           0         []                            \n",
      "                                                                                                  \n",
      " gru_6 (GRU)                 [(None, 256),                251904    ['input_11[0][0]']            \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " gru_7 (GRU)                 [(None, None, 256),          269568    ['input_12[0][0]',            \n",
      "                              (None, 256)]                           'gru_6[0][1]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, None, 93)             23901     ['gru_7[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 545373 (2.08 MB)\n",
      "Trainable params: 545373 (2.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4d52c92-71c1-483a-b4b8-36134157a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_data shape: (3116, 107, 70)\n",
      "WARNING:tensorflow:6 out of the last 684 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8acfdbe430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 198ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,1,1,93) (1,256) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m    101\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m encoder_input_data[seq_index: seq_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 102\u001b[0m     decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_texts[seq_index])\n",
      "Cell \u001b[0;32mIn[48], line 74\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     70\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# Predict next token and states from decoder\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     output_tokens, h \u001b[38;5;241m=\u001b[39m decoder_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43m[\u001b[49m\u001b[43mtarget_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates_value\u001b[49m)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Sample a token\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,1,1,93) (1,256) "
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"gru_model.keras\")\n",
    "\n",
    "latent_dim = 256\n",
    "encoder_inputs = model.input[0]\n",
    "\n",
    "encoder_gru = model.layers[2]\n",
    "_, state_h_enc = encoder_gru.output\n",
    "\n",
    "encoder_states = [state_h_enc]\n",
    "\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "decoder_inputs = model.input[1]\n",
    "\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_states_inputs = [decoder_state_input_h]\n",
    "\n",
    "decoder_gru = model.layers[3]\n",
    "\n",
    "decoder_outputs, state_h_dec = decoder_gru(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_states = [state_h_dec]\n",
    "\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, len(target_token_index)), dtype=np.float32)\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == \"\\n\" or\n",
    "            len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, len(target_token_index)), dtype=np.float32)\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        states_value = [h]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "print(\"encoder_input_data shape:\", encoder_input_data.shape)\n",
    "\n",
    "for seq_index in range(20):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad54416f-f80e-4331-b3ce-8ad4584202e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_data shape: (3116, 107, 70)\n",
      "input_seq shape for seq_index=0: (1, 107, 70)\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder_input_data shape:\", encoder_input_data.shape)  # should be (num_samples, max_encoder_seq_length, num_encoder_tokens)\n",
    "print(\"input_seq shape for seq_index=0:\", encoder_input_data[0:1].shape)  # should be (1, max_encoder_seq_length, num_encoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9aa1179-3baa-453d-b42c-7676fc55806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 683 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8acd3583a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "target_seq ndim: 3\n",
      "target_seq shape: (1, 1, 93)\n",
      "states_value ndim: [1]\n",
      "states_value shapes: [(256,)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,1,1,93) (1,256) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      2\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m encoder_input_data[seq_index : seq_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_texts[seq_index])\n",
      "Cell \u001b[0;32mIn[45], line 53\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates_value ndim:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m states_value])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates_value shapes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [s\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m states_value])\n\u001b[0;32m---> 53\u001b[0m output_tokens, h \u001b[38;5;241m=\u001b[39m decoder_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43m[\u001b[49m\u001b[43mtarget_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates_value\u001b[49m)\n\u001b[1;32m     55\u001b[0m sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[1;32m     56\u001b[0m sampled_char \u001b[38;5;241m=\u001b[39m reverse_target_char_index[sampled_token_index]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,1,1,93) (1,256) "
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
